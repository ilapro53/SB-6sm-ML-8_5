{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Сервер"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Скрипт для установки/запуска сервера"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[sudo] password for ilapr: CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "!echo {getpass()} | sudo -S docker ps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aQJwYsTPdbB",
        "outputId": "f9a71327-9f93-48d2-f865-f8715567dd4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting start_server.sh\n"
          ]
        }
      ],
      "source": [
        "%%writefile start_server.sh\n",
        "echo\n",
        "echo server started\n",
        "docker run -t --rm -p 8501:8501 -v \"/mnt/o/study/ml_6/8.5/docker/my_model:/models/my_model\" -e MODEL_NAME=my_model tensorflow/serving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Запуск сервера"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[sudo] password for ilapr: \n",
            "server started\n",
            "2024-05-24 16:34:43.977981: I tensorflow_serving/model_servers/server.cc:77] Building single TensorFlow model file config:  model_name: my_model model_base_path: /models/my_model\n",
            "2024-05-24 16:34:43.978489: I tensorflow_serving/model_servers/server_core.cc:471] Adding/updating models.\n",
            "2024-05-24 16:34:43.978515: I tensorflow_serving/model_servers/server_core.cc:600]  (Re-)adding model: my_model\n",
            "2024-05-24 16:34:45.069737: I tensorflow_serving/core/basic_manager.cc:740] Successfully reserved resources to load servable {name: my_model version: 1}\n",
            "2024-05-24 16:34:45.069828: I tensorflow_serving/core/loader_harness.cc:68] Approving load for servable version {name: my_model version: 1}\n",
            "2024-05-24 16:34:45.070862: I tensorflow_serving/core/loader_harness.cc:76] Loading servable version {name: my_model version: 1}\n",
            "2024-05-24 16:34:45.095315: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /models/my_model/1\n",
            "2024-05-24 16:34:45.098677: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
            "2024-05-24 16:34:45.098717: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /models/my_model/1\n",
            "2024-05-24 16:34:45.409742: I external/org_tensorflow/tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
            "2024-05-24 16:34:45.411982: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:234] Restoring SavedModel bundle.\n",
            "2024-05-24 16:34:45.594151: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:218] Running initialization op on SavedModel bundle at path: /models/my_model/1\n",
            "2024-05-24 16:34:45.603048: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:317] SavedModel load for tags { serve }; Status: success: OK. Took 507743 microseconds.\n",
            "2024-05-24 16:34:45.604762: I tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:82] No warmup data file found at /models/my_model/1/assets.extra/tf_serving_warmup_requests\n",
            "2024-05-24 16:34:45.752937: I tensorflow_serving/core/loader_harness.cc:97] Successfully loaded servable version {name: my_model version: 1}\n",
            "2024-05-24 16:34:45.756653: I tensorflow_serving/model_servers/server_core.cc:492] Finished adding/updating models\n",
            "2024-05-24 16:34:45.756779: I tensorflow_serving/model_servers/server.cc:121] Using InsecureServerCredentials\n",
            "2024-05-24 16:34:45.756837: I tensorflow_serving/model_servers/server.cc:388] Profiler service is enabled\n",
            "2024-05-24 16:34:45.761156: I tensorflow_serving/model_servers/server.cc:423] Running gRPC ModelServer at 0.0.0.0:8500 ...\n",
            "[warn] getaddrinfo: address family for nodename not supported\n",
            "2024-05-24 16:34:45.762341: I tensorflow_serving/model_servers/server.cc:444] Exporting HTTP/REST API at:localhost:8501 ...\n",
            "[evhttp_server.cc : 250] NET_LOG: Entering the event loop ...\n",
            "2024-05-24 16:35:39.255282: W external/org_tensorflow/tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: FAILED_PRECONDITION: Could not find variable sequential/dense_1/bias. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status error message=Resource localhost/sequential/dense_1/bias/N10tensorflow3VarE does not exist.\n",
            "\t [[{{function_node __inference_serving_default_54223}}{{node sequential_1/dense_1_2/Add/ReadVariableOp}}]]\n",
            "2024-05-24 16:35:39.266444: W external/org_tensorflow/tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: ABORTED: Stopping remaining executors.\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "!echo {getpass()} | sudo -S sh start_server.sh"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
